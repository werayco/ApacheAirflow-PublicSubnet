name: push-dags-to-ec2

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Debug workspace
        run: |
          echo "Workspace:"
          pwd
          ls -la
          echo "Dags folder:"
          ls -la dags

      - name: Copy DAGs to Bastion
        uses: appleboy/scp-action@v0.1.7
        with:
          host: ${{ secrets.BASTION_HOST }}
          username: ${{ secrets.BASTION_USERNAME }}
          key: ${{ secrets.BASTION_SSH_KEY }}
          port: ${{ secrets.BASTION_PORT }}
          source: "dags/*"
          target: "~/app/dags/"
          overwrite: true

      - name: Copy from Bastion to EC2 and Restart Airflow
        uses: appleboy/ssh-action@v0.1.7
        with:
          host: ${{ secrets.BASTION_HOST }}
          username: ${{ secrets.BASTION_USERNAME }}
          key: ${{ secrets.BASTION_SSH_KEY }}
          port: ${{ secrets.BASTION_PORT }}
          script: |
            echo "Copying DAGs from Bastion â†’ EC2..."
            
            # First, ensure the target directory exists on EC2
            ssh -o StrictHostKeyChecking=no -i /home/ubuntu/airflow.pem ubuntu@${{ secrets.EC2_HOST }} "mkdir -p /home/ubuntu/app/dags"
            
            # Copy all DAG files from bastion to EC2
            scp -o StrictHostKeyChecking=no -i /home/ubuntu/airflow.pem -r /home/ubuntu/app/dags/* ubuntu@${{ secrets.EC2_HOST }}:/home/ubuntu/app/dags/
            
            echo "Restarting Airflow containers..."
            ssh -o StrictHostKeyChecking=no -i /home/ubuntu/airflow.pem ubuntu@${{ secrets.EC2_HOST }} "
              cd /home/ubuntu/app && \
              docker-compose restart airflow-scheduler airflow-worker
            "
            
            echo "Airflow Restarted Successfully"